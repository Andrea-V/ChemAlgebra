{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d4d0c3c-bc77-4ecc-9a32-b32028dd446d",
   "metadata": {},
   "source": [
    "# Build new balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd0e2a6-a1e0-42ce-95f8-94d31532f8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import tqdm, os\n",
    "\n",
    "from rdkit import Chem\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# shut up warning\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "ADD_Hs = True\n",
    "PARTIAL_BALANCE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464c3a25-4a89-4ab6-a46c-89b4b8c150a5",
   "metadata": {},
   "source": [
    "## New dataset of balanced reactions\n",
    "### helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65df9643-7c60-43f5-a9c5-bec15f594f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "from rdkit.Chem import rdDepictor\n",
    "rdDepictor.SetPreferCoordGen(True)\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from IPython.display import SVG\n",
    "\n",
    "# actual function to draw molecule\n",
    "def drawMyMol(mol, fname, image_size, myFontSize):\n",
    "    d = rdMolDraw2D.MolDraw2DCairo(image_size[0], image_size[1])\n",
    "    d.SetFontSize(myFontSize)\n",
    "    #print(d.FontSize())\n",
    "    d.DrawMolecule(mol)\n",
    "    d.FinishDrawing()\n",
    "    d.WriteDrawingText(fname)\n",
    "\n",
    "# draw and store the reactions of interest\n",
    "def draw_and_store_reactions(c, dirpath, reactants, reagents, products, pred):\n",
    "    \n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)\n",
    "    \n",
    "    reactants_smiles = \".\".join([ Chem.MolToSmiles(Chem.RemoveHs(react)) for react in reactants ])\n",
    "    reactants_mol = Chem.MolFromSmiles(reactants_smiles)\n",
    "\n",
    "    reagents_smiles = \".\".join([ Chem.MolToSmiles(Chem.RemoveHs(reag)) for reag in reagents ])\n",
    "    reagents_mol = Chem.MolFromSmiles(reagents_smiles)\n",
    "\n",
    "    products_smiles = \".\".join([ Chem.MolToSmiles(Chem.RemoveHs(prod)) for prod in products ])\n",
    "    products_mol = Chem.MolFromSmiles(products_smiles)\n",
    "\n",
    "    if not pred:\n",
    "        pred_smiles = \"\"\n",
    "    else:\n",
    "        pred_smiles = Chem.MolToSmiles(pred)\n",
    "\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    reacts_imgs = []\n",
    "\n",
    "    IMAGE_sz = 500\n",
    "    MPL_sz = 200\n",
    "    FONTSIZE = 40\n",
    "    \n",
    "    keep = \"y\"\n",
    "    if keep == \"y\":\n",
    "        dirpath = \"./recovered_reactions_plots/\" + str(c) + \"/\"\n",
    "        os.makedirs(dirpath, exist_ok=True)\n",
    "\n",
    "        #for i, img in enumerate(reacts_imgs):\n",
    "        #    img.save(os.path.join(dirpath, \"react_\" + str(i) + \".png\"))\n",
    "\n",
    "        for i, react in enumerate(reactants):\n",
    "            drawMyMol(react,  os.path.join(dirpath, \"react_\" + str(i) + \".png\"), image_size=(IMAGE_sz, IMAGE_sz), myFontSize=FONTSIZE)\n",
    "\n",
    "        for i, reag in enumerate(reagents):\n",
    "            drawMyMol(reag,  os.path.join(dirpath, \"reag_\" + str(i) +\".png\"), image_size=(IMAGE_sz, IMAGE_sz), myFontSize=FONTSIZE)\n",
    "\n",
    "        if pred is not None:\n",
    "            drawMyMol(pred,  os.path.join(dirpath, \"pred_\" + str(i) + \".png\"), image_size=(IMAGE_sz, IMAGE_sz), myFontSize=FONTSIZE)\n",
    "\n",
    "        for i, prod in enumerate(products):\n",
    "            drawMyMol(prod,  os.path.join(dirpath, \"ground_truth_\" + str(i) + \".png\"), image_size=(IMAGE_sz, IMAGE_sz),  myFontSize=FONTSIZE)\n",
    "\n",
    "        #reag_img.save(os.path.join(dirpath,\"reag.png\"))\n",
    "        #pred_img.save(os.path.join(dirpath,\"pred.png\"))\n",
    "        #gt_img.save(os.path.join(dirpath, \"ground_truth.png\"))\n",
    "\n",
    "        with open(os.path.join(dirpath, \"smiles.txt\"), \"w\") as fp:\n",
    "            fp.write(\n",
    "                \"REACTANTS   :\" + reactants_smiles + \"\\n\" + \n",
    "                \"REAGENTS    :\" + reagents_smiles + \"\\n\" +\n",
    "                \"PREDICTION  :\" + pred_smiles + \"\\n\" +\n",
    "                \"GROUND TRUTH:\" + products_smiles + \"\\n\"\n",
    "            )\n",
    "\n",
    "\n",
    "# updated version of atom_count, consider also formal charge into the atom symbol\n",
    "def atom_count(molecules):\n",
    "    def get_symbol_with_charge(atom):\n",
    "        symbol = atom.GetSymbol()\n",
    "        charge = atom.GetFormalCharge()\n",
    "        \n",
    "        if charge == 1:\n",
    "            symbol += \"+\"\n",
    "        elif charge == -1:\n",
    "            symbol += \"-\"\n",
    "        elif charge > 1:\n",
    "            symbol += \"+\" + str(charge)\n",
    "        elif charge < -1:\n",
    "            symbol += \"-\" + str(-charge)\n",
    "            \n",
    "        return symbol\n",
    "        \n",
    "    counter, num_atoms = Counter(), 0\n",
    "    for mol in molecules:\n",
    "        counter += Counter([get_symbol_with_charge(atom) for atom in mol.GetAtoms()]) \n",
    "        num_atoms += mol.GetNumAtoms()\n",
    "    \n",
    "    return counter, num_atoms\n",
    "\n",
    "\n",
    "def make_balanced(idx, reactants, products, plot=False):\n",
    "    reactants_counter, reactants_n_atoms = atom_count(reactants)\n",
    "    products_counter, products_n_atoms = atom_count(products)\n",
    "    \n",
    "    # reaction is already balanced\n",
    "    if reactants_counter == products_counter:\n",
    "        return True, False, reactants, products\n",
    "    \n",
    "    # if not already balanced, we need to rebelanced either reactants and products (or both)\n",
    "    remaining_reactants_counter = reactants_counter - products_counter\n",
    "    remaining_products_counter = products_counter - reactants_counter\n",
    "    \n",
    "    # add a new molecule with remaining reactants' atoms to the products\n",
    "    if remaining_reactants_counter:\n",
    "        init_smiles = \"[\" + \"][\".join(list(remaining_reactants_counter.elements())) + \"]\"\n",
    "        try:\n",
    "            canon_smiles = Chem.CanonSmiles(init_smiles)\n",
    "            remaining_mol = Chem.AddHs(Chem.MolFromSmiles(canon_smiles))            \n",
    "            remaining_counter_after, _ = atom_count([remaining_mol])\n",
    "            new_products = products + [remaining_mol]            \n",
    "        except:\n",
    "            return False, False, reactants, products\n",
    "    else:\n",
    "        new_products = products\n",
    "\n",
    "    # add a new molecule with remaining products' atoms to the reactants\n",
    "    if remaining_products_counter:\n",
    "        init_smiles = \"[\" + \"][\".join(list(remaining_products_counter.elements())) + \"]\"\n",
    "        try:\n",
    "            canon_smiles = Chem.CanonSmiles(init_smiles)\n",
    "            remaining_mol = Chem.AddHs(Chem.MolFromSmiles(canon_smiles))            \n",
    "            remaining_counter_after, _ = atom_count([remaining_mol])\n",
    "            new_reactants = reactants + [remaining_mol]\n",
    "        except:\n",
    "            return False, False, reactants, products\n",
    "    else:\n",
    "        new_reactants = reactants\n",
    "\n",
    "    if plot:\n",
    "        draw_and_store_reactions(idx, \"./recovered_reactions_plots\", new_reactants, reagents, new_products, None)\n",
    "        \n",
    "    return True, True, new_reactants, new_products\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553d1940-e69e-4fe6-8ded-e739a688895c",
   "metadata": {},
   "source": [
    " ### Populate balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3c22b0-24db-4720-868c-b34d72d2eb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# populate balanced dataset\n",
    "balanced_dataset = {\n",
    "    \"TR\": {\n",
    "        \"fp_src\": open('./raw_data/DataSet-USPTO-main/MIT_separated/src-train.txt', 'r'),\n",
    "        \"fp_tgt\": open('./raw_data/DataSet-USPTO-main/MIT_separated/tgt-train.txt', 'r'),\n",
    "        \"reagents\" : [],\n",
    "        \"reactants\": [],\n",
    "        \"products\" : [],\n",
    "        \"balanced_count\": 0,\n",
    "        \"recovered_count\": 0\n",
    "    },\n",
    "    \"VL\":{\n",
    "        \"fp_src\": open('./raw_data/DataSet-USPTO-main/MIT_separated/src-valid.txt', 'r'),\n",
    "        \"fp_tgt\": open('./raw_data/DataSet-USPTO-main/MIT_separated/tgt-valid.txt', 'r'),        \n",
    "        \"reagents\" : [],\n",
    "        \"reactants\": [],\n",
    "        \"products\" : [],\n",
    "        \"balanced_count\": 0,\n",
    "        \"recovered_count\": 0        \n",
    "    },\n",
    "    \"TS\":{\n",
    "        \"fp_src\": open('./raw_data/DataSet-USPTO-main/MIT_separated/src-test.txt', 'r'),\n",
    "        \"fp_tgt\": open('./raw_data/DataSet-USPTO-main/MIT_separated/tgt-test.txt', 'r'),        \n",
    "        \"reagents\" : [],\n",
    "        \"reactants\": [],\n",
    "        \"products\" : [],\n",
    "        \"balanced_count\": 0,\n",
    "        \"recovered_count\": 0        \n",
    "    }\n",
    "}\n",
    "\n",
    "# load data in memory\n",
    "for data_split in [\"TR\", \"VL\", \"TS\"]:\n",
    "    src_lines = balanced_dataset[data_split][\"fp_src\"].readlines()\n",
    "    tgt_lines = balanced_dataset[data_split][\"fp_tgt\"].readlines()\n",
    "    balanced_dataset[data_split][\"fp_src\"].close()\n",
    "    balanced_dataset[data_split][\"fp_tgt\"].close()\n",
    "    del balanced_dataset[data_split][\"fp_src\"]\n",
    "    del balanced_dataset[data_split][\"fp_tgt\"]\n",
    "    \n",
    "    remove_whitespaces = str.maketrans('', '', string.whitespace) # used for removing whitespaces.\n",
    "    c = 0\n",
    "    for src_line, tgt_line in tqdm.tqdm(zip(src_lines, tgt_lines), total=len(src_lines)):\n",
    "     \n",
    "        c += 1\n",
    "        #if c > 100:\n",
    "        #     break\n",
    "    \n",
    "        src_line_splits = src_line.split(\">\")\n",
    "        assert(len(src_line_splits) == 2)\n",
    "        reactants_nonsplit, reagents_nonsplit = src_line_splits[0].translate(remove_whitespaces), src_line_splits[1].translate(remove_whitespaces)\n",
    "\n",
    "        products_nonsplit = tgt_line.translate(remove_whitespaces)\n",
    "\n",
    "        reactants = reactants_nonsplit.split(\".\")\n",
    "        reagents  = reagents_nonsplit.split(\".\")\n",
    "        products  = products_nonsplit.split(\".\")\n",
    "        \n",
    "        # sometimes reagents are empty, remove empty strings\n",
    "        if reagents == [\"\"]:\n",
    "            #print(\"reagents are empty string!\")\n",
    "            reagents = []\n",
    "            \n",
    "        if ADD_Hs:\n",
    "            reactants = [Chem.AddHs(Chem.MolFromSmiles(reactant)) for reactant in reactants ]\n",
    "            reagents = [Chem.AddHs(Chem.MolFromSmiles(reagent)) for reagent in reagents ]\n",
    "            products = [Chem.AddHs(Chem.MolFromSmiles(product)) for product in products ]\n",
    "        else:\n",
    "            reactants = [Chem.MolFromSmiles(reactant) for reactant in reactants ]\n",
    "            reagents = [Chem.MolFromSmiles(reagent) for reagent in reagents ]\n",
    "            products = [Chem.MolFromSmiles(product) for product in products ]\n",
    "    \n",
    "        reactants_counter, reactants_n_atoms = atom_count(reactants)\n",
    "        products_counter, products_n_atoms = atom_count(products)\n",
    "        \n",
    "        if c < 100:\n",
    "            plot = True\n",
    "        else:\n",
    "            plot = False\n",
    "            break\n",
    "            \n",
    "        balanced, recovered, out_reactants, out_products = make_balanced(c, reactants, products, plot)\n",
    "        \n",
    "        # nothing that can be done, go to next reaction\n",
    "        if not balanced:\n",
    "            # if partial balance, add the unbalanced reaction anyway\n",
    "            if PARTIAL_BALANCE:\n",
    "                balanced_dataset[data_split][\"reactants\"].append(out_reactants)\n",
    "                balanced_dataset[data_split][\"reagents\"].append(reagents)\n",
    "                balanced_dataset[data_split][\"products\"].append(out_products)\n",
    "            continue\n",
    "        else:\n",
    "            balanced_dataset[data_split][\"balanced_count\"] += 1\n",
    "            if recovered:\n",
    "                balanced_dataset[data_split][\"recovered_count\"] += 1\n",
    "                \n",
    "        # final double check that the reaction is now balanced\n",
    "        out_reactants_counter, _ = atom_count(out_reactants)\n",
    "        out_products_counter, _ = atom_count(out_products)\n",
    "        \n",
    "        # reaction is now balanced for sure\n",
    "        if out_reactants_counter == out_products_counter:\n",
    "            balanced_dataset[data_split][\"reactants\"].append(out_reactants)\n",
    "            balanced_dataset[data_split][\"reagents\"].append(reagents)\n",
    "            balanced_dataset[data_split][\"products\"].append(out_products)\n",
    "            \n",
    "        else:\n",
    "            print(\"Rebalancing did not work!\")\n",
    "            assert False\n",
    "       \n",
    "    assert len(balanced_dataset[data_split][\"reactants\"]) == len(balanced_dataset[data_split][\"reagents\"]) == len(balanced_dataset[data_split][\"products\"])\n",
    "    balanced_dataset[data_split][\"len\"] = len(balanced_dataset[data_split][\"reactants\"])\n",
    "    \n",
    "print(\"- Balanced dataset completed!\")\n",
    "print(\"- TR reactions:\", balanced_dataset[\"TR\"][\"balanced_count\"], \"of which\", balanced_dataset[\"TR\"][\"recovered_count\"], \"have been recovered.\")\n",
    "print(\"- VL reactions:\", balanced_dataset[\"VL\"][\"balanced_count\"], \"of which\", balanced_dataset[\"VL\"][\"recovered_count\"], \"have been recovered.\")\n",
    "print(\"- TS reactions:\", balanced_dataset[\"TS\"][\"balanced_count\"], \"of which\", balanced_dataset[\"TS\"][\"recovered_count\"], \"have been recovered.\")\n",
    "\n",
    "print(\"- TR recovered ratio:\", balanced_dataset[\"TR\"][\"recovered_count\"] / balanced_dataset[\"TR\"][\"balanced_count\"])\n",
    "print(\"- VL recovered ratio:\", balanced_dataset[\"VL\"][\"recovered_count\"] / balanced_dataset[\"VL\"][\"balanced_count\"])\n",
    "print(\"- TS recovered ratio:\", balanced_dataset[\"TS\"][\"recovered_count\"] / balanced_dataset[\"TS\"][\"balanced_count\"])\n",
    "\n",
    "\n",
    "total_dataset_len = balanced_dataset[\"TR\"][\"len\"] + balanced_dataset[\"VL\"][\"len\"] + balanced_dataset[\"TS\"][\"len\"]\n",
    "\n",
    "tr_ratio = balanced_dataset[\"TR\"][\"len\"] / total_dataset_len\n",
    "vl_ratio = balanced_dataset[\"VL\"][\"len\"] / total_dataset_len\n",
    "ts_ratio = balanced_dataset[\"TS\"][\"len\"] / total_dataset_len\n",
    "\n",
    "print(\"TOT len:\", total_dataset_len)\n",
    "print(\"TR len:\", balanced_dataset[\"TR\"][\"len\"])\n",
    "print(\"VL len:\", balanced_dataset[\"VL\"][\"len\"])\n",
    "print(\"TS len:\", balanced_dataset[\"TS\"][\"len\"])\n",
    "\n",
    "print(\"Balanced dataset tr/vl/ts split is:\", round(tr_ratio, 2), \"/\", round(vl_ratio, 2), \"/\", round(ts_ratio, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8252f3-bfc5-48df-846f-c34124748a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# LAST STEP: store the (partially) balanced dataset:\n",
    "# store the data\n",
    "if PARTIAL_BALANCE:\n",
    "    dataset_name = \"USPTO_partially_balanced\"\n",
    "else:\n",
    "    dataset_name = \"USPTO_balanced\"\n",
    "    \n",
    "if not os.path.exists(\"./\" + dataset_name):\n",
    "    os.makedirs(\"./\" + dataset_name)\n",
    "\n",
    "for data_split, split_name in [[\"TR\", \"train\"], [\"VL\", \"valid\"],[\"TS\", \"test\"]]:\n",
    "    with open(\"./\" + dataset_name + \"/src-\" + split_name + \".txt\", \"w\") as src_fp:\n",
    "        with open(\"./\" + dataset_name + \"/tgt-\" + split_name + \".txt\", \"w\") as dst_fp:\n",
    "\n",
    "            reactants_data = balanced_dataset[data_split][\"reactants\"]\n",
    "            reagents_data  = balanced_dataset[data_split][\"reagents\"]\n",
    "            products_data  = balanced_dataset[data_split][\"products\"]\n",
    "            \n",
    "            print(\"Storing\", data_split, \"set..\")\n",
    "            for reactants, reagents, products in tqdm.tqdm(zip(reactants_data, reagents_data, products_data), total=len(reactants_data)):\n",
    "                \n",
    "                # reomve hs only in this case, where i want to compare with vanilla USPTO\n",
    "                if PARTIAL_BALANCE:\n",
    "                    reactants_smiles = [ Chem.CanonSmiles(Chem.MolToSmiles(Chem.RemoveHs(mol))) for mol in reactants ]\n",
    "                    reagents_smiles  = [ Chem.CanonSmiles(Chem.MolToSmiles(Chem.RemoveHs(mol))) for mol in reagents ]\n",
    "                    products_smiles  = [ Chem.CanonSmiles(Chem.MolToSmiles(Chem.RemoveHs(mol))) for mol in products ]\n",
    "                else:\n",
    "                    reactants_smiles = [ Chem.CanonSmiles(Chem.MolToSmiles(mol)) for mol in reactants ]\n",
    "                    reagents_smiles  = [ Chem.CanonSmiles(Chem.MolToSmiles(mol)) for mol in reagents ]\n",
    "                    products_smiles  = [ Chem.CanonSmiles(Chem.MolToSmiles(mol)) for mol in products ]\n",
    "                \n",
    "                reactants_line = \".\".join(reactants_smiles)\n",
    "                reagents_line = \".\".join(reagents_smiles)\n",
    "                products_line = \".\".join(products_smiles)\n",
    "                \n",
    "                if reagents_line != \"\":\n",
    "                    src_line = reactants_line + \".\" + reagents_line + \"\\n\"\n",
    "                    tgt_line = products_line + \".\" + reagents_line + \"\\n\"\n",
    "                else:\n",
    "                    src_line = reactants_line + \"\\n\"\n",
    "                    tgt_line = products_line + \"\\n\"\n",
    "                    \n",
    "                src_fp.write(src_line)\n",
    "                dst_fp.write(tgt_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3b1274-bc0c-4f7b-914c-4fc7974a3894",
   "metadata": {},
   "source": [
    "## store data in pickle format for training chemformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874d1788-34c5-4744-81b0-eac60d81a490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dataset_to_pickle(dataset, add_hs=False):\n",
    "    data = pd.DataFrame(columns=[\"reactants_mol\", \"products_mol\", \"reagents_mol\", \"set\"])\n",
    "    \n",
    "    data_split_to_set = {\n",
    "        \"TR\" : \"train\",\n",
    "        \"VL\" : \"valid\",\n",
    "        \"TS\" : \"test\"\n",
    "    }\n",
    "    \n",
    "    for data_split in [\"TR\", \"VL\", \"TS\"]:    \n",
    "        current_data_split = dataset[data_split]\n",
    "        c = 0\n",
    "        \n",
    "        for reactants, reagents, products in tqdm.tqdm(zip(current_data_split[\"reactants\"], current_data_split[\"reagents\"], current_data_split[\"products\"]), total=current_data_split[\"len\"]):\n",
    "        \n",
    "            if c > 100:\n",
    "                break\n",
    "        \n",
    "            # remove hs only in this case, where i want to compare with vanilla USPTO\n",
    "            if not add_hs:\n",
    "                reactants_smiles = [ Chem.CanonSmiles(Chem.MolToSmiles(Chem.RemoveHs(mol))) for mol in reactants ]\n",
    "                reagents_smiles  = [ Chem.CanonSmiles(Chem.MolToSmiles(Chem.RemoveHs(mol))) for mol in reagents ]\n",
    "                products_smiles  = [ Chem.CanonSmiles(Chem.MolToSmiles(Chem.RemoveHs(mol))) for mol in products ]\n",
    "            else:\n",
    "                reactants_smiles = [ Chem.CanonSmiles(Chem.MolToSmiles(mol)) for mol in reactants ]\n",
    "                reagents_smiles  = [ Chem.CanonSmiles(Chem.MolToSmiles(mol)) for mol in reagents ]\n",
    "                products_smiles  = [ Chem.CanonSmiles(Chem.MolToSmiles(mol)) for mol in products ]\n",
    "\n",
    "            reactants_line = \".\".join(reactants_smiles)\n",
    "            reagents_line = \".\".join(reagents_smiles)\n",
    "            products_line = \".\".join(products_smiles)\n",
    "\n",
    "            if add_hs:\n",
    "                reactants = Chem.AddHs(Chem.MolFromSmiles(reactants_line))\n",
    "                reagents = Chem.AddHs(Chem.MolFromSmiles(reagents_line))\n",
    "                products = Chem.AddHs(Chem.MolFromSmiles(products_line))\n",
    "            else:\n",
    "                reactants = Chem.RemoveHs(Chem.MolFromSmiles(reactants_line))\n",
    "                reagents = Chem.RemoveHs(Chem.MolFromSmiles(reagents_line))\n",
    "                products = Chem.RemoveHs(Chem.MolFromSmiles(products_line))\n",
    "\n",
    "            data.loc[len(data.index)] = [reactants, reagents, products, data_split_to_set[data_split] ]    \n",
    "            \n",
    "    return data\n",
    "\n",
    "# store data in pickle format for training chemformer\n",
    "if PARTIAL_BALANCE:\n",
    "    subdir = \"USPTO_partially_balanced\"\n",
    "    add_hs = False\n",
    "    store_name = \"uspto_partially_balanced_prot3.pickle\"\n",
    "else:\n",
    "    subdir = \"USPTO_balanced\"\n",
    "    add_hs = True\n",
    "    store_name = \"uspto_balanced_prot3.pickle\"\n",
    "    \n",
    "if not os.path.exists(\"./pickle_datasets/\" + subdir + \"/\"):\n",
    "    os.makedirs(\"./pickle_datasets/\" + subdir + \"/\")    \n",
    "\n",
    "print(\"Converting dataset to pickle...\")\n",
    "pickle_data = convert_dataset_to_pickle(balanced_dataset, add_hs)\n",
    "pickle_data.to_pickle(\"./pickle_datasets/\" + subdir + \"/\" + store_name, protocol=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc29e9e-ae57-48c0-84a0-0d94355329a3",
   "metadata": {},
   "source": [
    "# Add whitespace to dataset for Molecular Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68776ae1-8349-42c6-acef-1d3df217f232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, tqdm\n",
    "\n",
    "def smi_tokenizer(smi):\n",
    "    \"\"\"\n",
    "    Tokenize a SMILES molecule or reaction\n",
    "    \"\"\"\n",
    "    import re\n",
    "    pattern =  \"(\\[[^\\]]+]|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\\(|\\)|\\.|=|#|-|\\+|\\\\\\\\|\\/|:|~|@|\\?|>|\\*|\\$|\\%[0-9]{2}|[0-9]|\\{[0-9]+\\})\"\n",
    "    regex = re.compile(pattern)\n",
    "    \n",
    "    smi_lines = smi.split(\"\\n\")\n",
    "    \n",
    "    output = \"\"\n",
    "    for smi_line in smi_lines:\n",
    "        tokens = [token for token in regex.findall(smi_line)]\n",
    "            \n",
    "        try:\n",
    "            assert smi_line == ''.join(tokens)\n",
    "        except AssertionError:\n",
    "            print(\"SMI_LINE:\", smi_line)\n",
    "            print(\"TOKENS:\", tokens)\n",
    "            \n",
    "            remaining = regex.sub(\"\", smi_line)\n",
    "            \n",
    "            print(\"REMAINING:\", remaining)\n",
    "            \n",
    "            assert False\n",
    "            \n",
    "        output += ' '.join(tokens) + \"\\n\"\n",
    "        \n",
    "    return output\n",
    "\n",
    "\n",
    "## MAIN ##\n",
    "\n",
    "if not os.path.exists(\"./USPTO_balanced_tokenized/\"):\n",
    "    os.makedirs(\"./USPTO_balanced_tokenized/\")\n",
    "\n",
    "    \n",
    "_, _, filenames = next(os.walk(\"./USPTO_balanced/\"))\n",
    "\n",
    "for filename in filenames:\n",
    "    if not filename.endswith(\".txt\"):\n",
    "        continue\n",
    "\n",
    "    #print(\"--\", filename)\n",
    "\n",
    "    with open(\"./USPTO_balanced/\" + filename, \"r\") as fp:\n",
    "        smi = fp.read()\n",
    "        tokens = smi_tokenizer(smi)\n",
    "\n",
    "    with open(\"./USPTO_balanced_tokenized/\" + filename, \"w\") as fp:\n",
    "        fp.write(tokens)\n",
    "\n",
    "print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa174019-de98-4971-8b4b-760825296a37",
   "metadata": {},
   "source": [
    "# Create augmentations by changing stoichiometric coefficients\n",
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2c739c-a9be-4807-9ca4-dbada0795faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chempy\n",
    "from chempy import balance_stoichiometry\n",
    "import sympy, random, numpy as np\n",
    "import copy\n",
    "from rdkit.Chem.rdMolDescriptors import CalcMolFormula\n",
    "\n",
    "def atom_count(molecules):\n",
    "    def get_symbol_with_charge(atom):\n",
    "        symbol = atom.GetSymbol()\n",
    "        charge = atom.GetFormalCharge()\n",
    "        \n",
    "        if charge == 1:\n",
    "            symbol += \"+\"\n",
    "        elif charge == -1:\n",
    "            symbol += \"-\"\n",
    "        elif charge > 1:\n",
    "            symbol += \"+\" + str(charge)\n",
    "        elif charge < -1:\n",
    "            symbol += \"-\" + str(-charge)\n",
    "            \n",
    "        return symbol\n",
    "        \n",
    "    counter, num_atoms = Counter(), 0\n",
    "    for mol in molecules:\n",
    "        counter += Counter([get_symbol_with_charge(atom) for atom in mol.GetAtoms()]) \n",
    "        num_atoms += mol.GetNumAtoms()\n",
    "    \n",
    "    return counter, num_atoms\n",
    "\n",
    "# builds a single augmentation of a reaction\n",
    "# params:\n",
    "# reactants, reagents, products: are assumed to be SMILES strings\n",
    "# base_k_set, add_k_set: set of values from which sample the stoichiometric coefficients\n",
    "#                      | the base_k_set is for the base coefficient, add_k_set is for the coeff of the added products\n",
    "def build_augmentation(reactants, reagents, products, aug_type, k_set, representation=\"smiles\"):\n",
    "    \n",
    "    if representation not in {\"formula\", \"smiles\"}:\n",
    "        raise ValueError(\"Unknown representation:\", representation)\n",
    "    \n",
    "    if representation == \"formula\":\n",
    "        reactants = [ CalcMolFormula(Chem.MolFromSmiles(r)) for r in reactants ]\n",
    "        reagents  = [ CalcMolFormula(Chem.MolFromSmiles(r)) for r in reagents  ]\n",
    "        products  = [ CalcMolFormula(Chem.MolFromSmiles(p)) for p in products  ]\n",
    "    \n",
    "    # if type 1 augmentation, then set all coeff for every molecule\n",
    "    if aug_type == 1:\n",
    "        base_k = random.choice(k_set)\n",
    "        \n",
    "        aug_reactants_list = [ \"{\" + str(base_k) + \"}\" + react for react in reactants + reagents ]\n",
    "        aug_products_list  = [ \"{\" + str(base_k) + \"}\" + prod for prod in products + reagents ]\n",
    "                \n",
    "    # if type 2 augmentation, select a different coefficient for each molecule    \n",
    "    elif aug_type == 2:\n",
    "        coeffs = { mol: random.choice(k_set) for mol in reactants + reagents + products }\n",
    "        k_min = random.randint(1, min(coeffs.values()))\n",
    "        \n",
    "        # first list: use sampled coeff.\n",
    "        # second list: add on lhs the excess products\n",
    "        aug_reactants_list = [\n",
    "            \"{\" + str(coeffs[react]) + \"}\" + react\n",
    "            for react in reactants + reagents\n",
    "        ] + [\n",
    "            \"{\" + str(coeffs[prod] - k_min) + \"}\" + prod \n",
    "            for prod in products if coeffs[prod] - k_min > 0\n",
    "        ]\n",
    "        \n",
    "        # this is specular to the list comprehension above, just for products\n",
    "        aug_products_list = [\n",
    "            \"{\" + str(coeffs[prod]) + \"}\" + prod\n",
    "            for prod in products + reagents\n",
    "        ] + [\n",
    "            \"{\" + str(coeffs[react] - k_min) + \"}\" + react \n",
    "            for react in reactants if coeffs[react] - k_min > 0\n",
    "        ]\n",
    "          \n",
    "    else:\n",
    "        raise ValueError(\"Unknown aug_type:\", aug_type)\n",
    "\n",
    "    random.shuffle(aug_reactants_list)\n",
    "    random.shuffle(aug_products_list)\n",
    "\n",
    "    aug_reactants = \".\".join(aug_reactants_list)\n",
    "    aug_products  = \".\".join(aug_products_list)\n",
    "    \n",
    "    return aug_reactants, aug_products\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5af754-177d-4ae1-85b0-24a5e978df90",
   "metadata": {},
   "source": [
    "## Make augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7c3c5f-a78a-4fe8-9d80-8e3195a2d7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_augmented_data_split(dataset_name, data_split, split_filename, n_augmentations, aug_type, k_set, representation):\n",
    "    path_prefix = \"./chemalebra_datasets/\"\n",
    "    if not os.path.exists(path_prefix + dataset_name):\n",
    "        os.makedirs(path_prefix + dataset_name)\n",
    "\n",
    "    with open(path_prefix + dataset_name + \"/src-\" + split_filename + \".txt\", \"w\") as src_fp:\n",
    "        with open(path_prefix + dataset_name + \"/tgt-\" + split_filename + \".txt\", \"w\") as dst_fp:\n",
    "\n",
    "            reactants_data = balanced_dataset[data_split][\"reactants\"]\n",
    "            reagents_data  = balanced_dataset[data_split][\"reagents\"]\n",
    "            products_data  = balanced_dataset[data_split][\"products\"]\n",
    "\n",
    "            for reactants, reagents, products in tqdm.tqdm(zip(reactants_data, reagents_data, products_data), total=len(reactants_data)):\n",
    "\n",
    "                reactants_smiles = [ Chem.CanonSmiles(Chem.MolToSmiles(Chem.AddHs(mol))) for mol in reactants ]\n",
    "                reagents_smiles  = [ Chem.CanonSmiles(Chem.MolToSmiles(Chem.AddHs(mol))) for mol in reagents ]\n",
    "                products_smiles  = [ Chem.CanonSmiles(Chem.MolToSmiles(Chem.AddHs(mol))) for mol in products ]\n",
    "\n",
    "                for _ in range(n_augmentations):\n",
    "                    aug_src, aug_tgt = build_augmentation(\n",
    "                        reactants_smiles, reagents_smiles, products_smiles,\n",
    "                        aug_type=aug_type,\n",
    "                        k_set=k_set,\n",
    "                        representation=representation\n",
    "                    )\n",
    "                    \n",
    "                    aug_src += \"\\n\"\n",
    "                    aug_tgt += \"\\n\"\n",
    "\n",
    "                    src_fp.write(aug_src)\n",
    "                    dst_fp.write(aug_tgt)    \n",
    "\n",
    "\n",
    "# second part: save the dataset on disk\n",
    "print(\"- Building starting dataset...\")\n",
    "for data_split, split_filename in [[\"TR\", \"train\"], [\"VL\", \"valid\"],[\"TS\", \"test\"]]:\n",
    "    build_augmented_data_split(\n",
    "        \"USPTO_augmented_start\", data_split, split_filename,\n",
    "        n_augmentations=1, aug_type=1, k_set=[1], representation=\"smiles\"\n",
    "    )\n",
    "    \n",
    "# TYPE 1 AUGMENTATIONS\n",
    "dataset_prefix = \"USPTO_augmented_type1\"\n",
    "\n",
    "print(\"Building augmentations type 1...\")\n",
    "for n_augm in [1, 5, 10]:\n",
    "    for rep in [\"smiles\", \"formula\"]:\n",
    "        print(\"- n_augmentations:\", n_augm, \", rep:\", rep)\n",
    "        dataset_name = dataset_prefix + \"_x\" + str(n_augm) + \"_\" + rep\n",
    "        \n",
    "        build_augmented_data_split(\n",
    "            dataset_name, data_split=\"TR\", split_filename=\"train\",\n",
    "            n_augmentations=n_augm, aug_type=1, k_set=[1, 2, 3, 4, 5], representation=rep\n",
    "        )\n",
    "        build_augmented_data_split(\n",
    "            dataset_name, data_split=\"VL\", split_filename=\"valid\",\n",
    "            n_augmentations=n_augm, aug_type=1, k_set=[1, 2, 3, 4, 5], representation=rep\n",
    "        )\n",
    "        build_augmented_data_split(\n",
    "            dataset_name, data_split=\"TS\", split_filename=\"test_in\",\n",
    "            n_augmentations=n_augm, aug_type=1, k_set=[1, 2, 3, 4, 5], representation=rep\n",
    "        )\n",
    "        build_augmented_data_split(\n",
    "            dataset_name, data_split=\"TR\", split_filename=\"test_x\",\n",
    "            n_augmentations=n_augm, aug_type=1, k_set=[6, 7, 8, 9, 10], representation=rep\n",
    "        )\n",
    "        build_augmented_data_split(\n",
    "            dataset_name, data_split=\"TS\", split_filename=\"test_out\",\n",
    "            n_augmentations=n_augm, aug_type=1, k_set=[6, 7, 8, 9, 10], representation=rep\n",
    "        )\n",
    "\n",
    "# TYPE 2 AUGMENTATIONS\n",
    "dataset_prefix = \"USPTO_augmented_type2\"\n",
    "\n",
    "print(\"Building augmentations type 2...\")\n",
    "for n_augm in [1, 5, 10]:\n",
    "    for rep in [\"smiles\", \"formula\"]:\n",
    "        print(\"- n_augmentations:\", n_augm, \", rep:\", rep)        \n",
    "        dataset_name = dataset_prefix + \"_x\" + str(n_augm) + \"_\" + rep\n",
    "        \n",
    "        build_augmented_data_split(\n",
    "            dataset_name, data_split=\"TR\", split_filename=\"train\",\n",
    "            n_augmentations=n_augm, aug_type=2, k_set=[1, 2, 3, 4, 5], representation=rep\n",
    "        )\n",
    "        build_augmented_data_split(\n",
    "            dataset_name, data_split=\"VL\", split_filename=\"valid\",\n",
    "            n_augmentations=n_augm, aug_type=2, k_set=[1, 2, 3, 4, 5], representation=rep\n",
    "        )\n",
    "        build_augmented_data_split(\n",
    "            dataset_name, data_split=\"TS\", split_filename=\"test_in\",\n",
    "            n_augmentations=n_augm, aug_type=2, k_set=[1, 2, 3, 4, 5], representation=rep\n",
    "        )\n",
    "        build_augmented_data_split(\n",
    "            dataset_name, data_split=\"TR\", split_filename=\"test_x\",\n",
    "            n_augmentations=n_augm, aug_type=2, k_set=[6, 7, 8, 9, 10], representation=rep\n",
    "        )\n",
    "        build_augmented_data_split(\n",
    "            dataset_name, data_split=\"TS\", split_filename=\"test_out\",\n",
    "            n_augmentations=n_augm, aug_type=2, k_set=[6, 7, 8, 9, 10], representation=rep\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da27957-6b9f-4caa-9454-fff2b273c149",
   "metadata": {},
   "source": [
    "# Tokenize datasets for Molecular Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7707f8-0a95-44d0-9e74-170fc78c332d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, tqdm\n",
    "\n",
    "def smi_tokenizer(smi):\n",
    "    \"\"\"\n",
    "    Tokenize a SMILES molecule or reaction\n",
    "    \"\"\"\n",
    "    import re\n",
    "    pattern =  \"(\\[[^\\]]+]|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\\(|\\)|\\.|=|#|-|\\+|\\\\\\\\|\\/|:|~|@|\\?|>|\\*|\\$|\\%[0-9]{2}|[0-9]|\\{[0-9]+\\})\"\n",
    "    regex = re.compile(pattern)\n",
    "    \n",
    "    smi_lines = smi.split(\"\\n\")\n",
    "    \n",
    "    output = \"\"\n",
    "    for smi_line in smi_lines:\n",
    "        tokens = [token for token in regex.findall(smi_line)]\n",
    "            \n",
    "        try:\n",
    "            assert smi_line == ''.join(tokens)\n",
    "        except AssertionError:\n",
    "            print(\"SMI_LINE:\", smi_line)\n",
    "            print(\"TOKENS:\", tokens)\n",
    "            \n",
    "            remaining = regex.sub(\"\", smi_line)\n",
    "            \n",
    "            print(\"REMAINING:\", remaining)\n",
    "            \n",
    "            assert False\n",
    "            \n",
    "        output += ' '.join(tokens) + \"\\n\"\n",
    "        \n",
    "    return output\n",
    "\n",
    "def smi_formula_tokenizer(smi):\n",
    "    \"\"\"\n",
    "    Tokenize a molecule formula\n",
    "    \"\"\"\n",
    "    import re\n",
    "    pattern =  \"([A-Z][a-z]?|\\.|-[0-9]*|\\+[0-9]*|[0-9]+|\\{[0-9]+\\})\"\n",
    "    regex = re.compile(pattern)\n",
    "    \n",
    "    smi_lines = smi.split(\"\\n\")\n",
    "    \n",
    "    output = \"\"\n",
    "    for smi_line in smi_lines:\n",
    "        tokens = [token for token in regex.findall(smi_line)]\n",
    "        \n",
    "        try:\n",
    "            assert smi_line == ''.join(tokens)\n",
    "        except AssertionError:\n",
    "            print(\"SMI_LINE:\", smi_line)\n",
    "            print(\"TOKENS:\", tokens)\n",
    "            \n",
    "            remaining = regex.sub(\"\", smi_line)\n",
    "            \n",
    "            print(\"REMAINING:\", remaining)\n",
    "            \n",
    "            assert False\n",
    "            \n",
    "        output += ' '.join(tokens) + \"\\n\"\n",
    "        \n",
    "    return output\n",
    "\n",
    "\n",
    "## MAIN ##\n",
    "\n",
    "if not os.path.exists(\"./tokenized_datasets/\"):\n",
    "    os.makedirs(\"./tokenized_datasets/\")\n",
    "\n",
    "_, subdirs, _ = next(os.walk(\"./new_datasets/\"))\n",
    "\n",
    "for subdir in tqdm.tqdm(subdirs):   \n",
    "    _, _, filenames = next(os.walk(\"./new_datasets/\" + subdir))\n",
    "    \n",
    "    print(\"- Tokenizing\", subdir, \"...\")\n",
    "    \n",
    "    if not os.path.exists(\"./tokenized_datasets/\" + subdir + \"/\"):\n",
    "        os.makedirs(\"./tokenized_datasets/\" + subdir + \"/\")    \n",
    "    \n",
    "    for filename in filenames:\n",
    "        if not filename.endswith(\".txt\"):\n",
    "            continue\n",
    "        \n",
    "        #print(\"--\", filename)\n",
    "        \n",
    "        with open(\"./new_datasets/\" + subdir + \"/\" + filename, \"r\") as fp:\n",
    "            smi = fp.read()\n",
    "            \n",
    "            if subdir.endswith(\"formula\"):\n",
    "                tokens = smi_formula_tokenizer(smi)\n",
    "            else:\n",
    "                tokens = smi_tokenizer(smi)\n",
    "                    \n",
    "        with open(\"./tokenized_datasets/\" + subdir + \"/\" + filename, \"w\") as fp:\n",
    "            fp.write(tokens)\n",
    "\n",
    "print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ea3642-8a3f-4095-b9d0-d9e1ec9016f3",
   "metadata": {},
   "source": [
    "# Compute metrics on models' predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e4b03a-86db-408a-85fe-97863309e57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, string, tqdm\n",
    "from rdkit import Chem\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "\n",
    "# shut up warning\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "\n",
    "def accuracies_top_1(mol_matching_fn, true, pred):\n",
    "    \n",
    "    #print(\"_TRUE_:\")\n",
    "    #pprint(true)\n",
    "    \n",
    "    #print(\"_PRED_:\")\n",
    "    #pprint(pred)\n",
    "    \n",
    "    # matched list contains the details of the match of two k-mol\n",
    "    matched_list = []\n",
    "    k_mol_true_list = []\n",
    "    k_mol_pred_list = []\n",
    "    \n",
    "    metrics_mol_only = { \"tp\": 0, \"fp\": 0, \"fn\": 0 }\n",
    "    metrics_mol_andk = { \"tp\": 0, \"fp\": 0, \"fn\": 0 }\n",
    "    \n",
    "    for k_mol in true:\n",
    "        k_mol_true_list.append({\n",
    "            \"matched\": False,\n",
    "            \"k\": k_mol[0],\n",
    "            \"mol\": k_mol[1]\n",
    "        })\n",
    "        \n",
    "    for k_mol in pred:\n",
    "        k_mol_pred_list.append({\n",
    "            \"matched\": False,\n",
    "            \"k\": k_mol[0],\n",
    "            \"mol\": k_mol[1]\n",
    "        })\n",
    "    \n",
    "    #print(\"_TRUE_:\")\n",
    "    #pprint(k_mol_true_list)\n",
    "    \n",
    "    #print(\"_PRED_:\")\n",
    "    #pprint(k_mol_pred_list)\n",
    "    \n",
    "    for i, true_k_mol in enumerate(k_mol_true_list):\n",
    "        k_true   = true_k_mol[\"k\"]\n",
    "        mol_true = true_k_mol[\"mol\"]\n",
    "        \n",
    "        # try to match the true mols to a predicted mols\n",
    "        for j, pred_k_mol in enumerate(k_mol_pred_list):\n",
    "            \n",
    "            k_pred   = pred_k_mol[\"k\"]\n",
    "            mol_pred = pred_k_mol[\"mol\"]\n",
    "            \n",
    "            try:\n",
    "                m = mol_matching_fn(mol_true, mol_pred)\n",
    "            except:\n",
    "                print(\"exception!\")\n",
    "                \n",
    "                print(\"pred_k_mol:\", pred_k_mol)\n",
    "                print(\"true:\", mol_true, \"pred:\", mol_pred)\n",
    "                #print(Chem.CanonSmiles(mol_true))\n",
    "                #print(Chem.CanonSmiles(mol_pred))\n",
    "                assert False\n",
    "            \n",
    "            if m:\n",
    "                if (not true_k_mol[\"matched\"]) and (not pred_k_mol[\"matched\"]):\n",
    "                    true_k_mol[\"matched\"] = True\n",
    "                    pred_k_mol[\"matched\"] = True\n",
    "                    \n",
    "                    # mol_only just cares about the molecule\n",
    "                    # mol_andk also cares about stoichiometric coefficients\n",
    "                    metrics_mol_only[\"tp\"] += 1\n",
    "                    \n",
    "                    matched = {\n",
    "                        \"true_idx\": i,\n",
    "                        \"pred_idx\": j,\n",
    "                        \"matched_mol\": True,\n",
    "                        \"matched_k\": False\n",
    "                    }\n",
    "                    \n",
    "                    # if both k_true and k_pred are not None, then try to\n",
    "                    # do an exact match\n",
    "                    if k_true and k_pred:\n",
    "                        metrics_mol_andk[\"tp\"] += min(k_true, k_pred)\n",
    "\n",
    "                        if k_true > k_pred:\n",
    "                            metrics_mol_andk[\"fn\"] += k_true - k_pred\n",
    "                        elif k_true < k_pred:\n",
    "                            metrics_mol_andk[\"fp\"] += k_pred - k_true\n",
    "\n",
    "                        matched[\"matched_k\"] = k_true == k_pred\n",
    "                        \n",
    "                    matched_list.append(matched)\n",
    "                    break\n",
    "    \n",
    "    # count number of remaining true mols\n",
    "    for kmol in k_mol_true_list:\n",
    "        if not kmol[\"matched\"]:\n",
    "            metrics_mol_only[\"fn\"] += 1\n",
    "            \n",
    "            # if coefficient is None, this is not  valid molecules for \n",
    "            # exact match metrics, therefore it is ignored\n",
    "            metrics_mol_andk[\"fn\"] += kmol[\"k\"] if kmol[\"k\"] else 0\n",
    "    \n",
    "    # count number of remaining pred mols\n",
    "    for kmol in k_mol_pred_list:\n",
    "        if not kmol[\"matched\"]:\n",
    "            metrics_mol_only[\"fp\"] += 1\n",
    "            \n",
    "            # same as above, if coef is None we do not consider it for exact match\n",
    "            metrics_mol_andk[\"fp\"] += kmol[\"k\"] if kmol[\"k\"] else 0\n",
    "    \n",
    "    # compute all statistics \n",
    "    #print(\"_MATCHED_:\")\n",
    "    #pprint(matched_list)\n",
    "    \n",
    "    #print(\"METRICS MOL ONLY:\")\n",
    "    #pprint(metrics_mol_only)\n",
    "\n",
    "    #print(\"METRICS MOL ANDK:\")\n",
    "    #pprint(metrics_mol_andk)\n",
    "    \n",
    "    tp = metrics_mol_only[\"tp\"]\n",
    "    fp = metrics_mol_only[\"fp\"]\n",
    "    fn = metrics_mol_only[\"fn\"]\n",
    "        \n",
    "    results_mol_only = {\n",
    "        \"accuracy\": 0.0 if (tp + fn + fp) == 0 else tp / (tp + fn + fp),\n",
    "        \"precision\": 0.0 if (tp + fp) == 0 else tp / (tp + fp),\n",
    "        \"recall\": 0.0 if (tp + fn) == 0 else tp / (tp + fn),\n",
    "        \"f1_score\": 0.0 if (2*tp + fp + fn) == 0 else (2*tp) / (2*tp + fp + fn),\n",
    "        \"hamming_loss\": 0.0 if (fp + fn + tp) == 0 else (fp + fn) / (fp + fn + tp)\n",
    "    }\n",
    "\n",
    "    tp = metrics_mol_andk[\"tp\"]\n",
    "    fp = metrics_mol_andk[\"fp\"]\n",
    "    fn = metrics_mol_andk[\"fn\"]\n",
    "    \n",
    "    results_mol_andk = {\n",
    "        \"accuracy\": 0.0 if (tp + fn + fp) == 0 else tp / (tp + fn + fp),\n",
    "        \"precision\": 0.0 if (tp + fp) == 0 else tp / (tp + fp),\n",
    "        \"recall\": 0.0 if (tp + fn) == 0 else tp / (tp + fn),\n",
    "        \"f1_score\": 0.0 if (2*tp + fp + fn) == 0 else (2*tp) / (2*tp + fp + fn),\n",
    "        \"hamming_loss\": 0.0 if (fp + fn + tp) == 0 else (fp + fn) / (fp + fn + tp)\n",
    "    }\n",
    "\n",
    "    exact_match = False\n",
    "    if fp == 0 and fn == 0:\n",
    "        exact_match = True\n",
    "    \n",
    "    #print(\"RESULT MOL ONLY:\")\n",
    "    #pprint(results_mol_only)\n",
    "\n",
    "    #print(\"RESULT MOL ANDK:\")\n",
    "    #pprint(results_mol_andk)    \n",
    "    \n",
    "    #input(\"next iteration...\")\n",
    "    \n",
    "    return exact_match, results_mol_only, results_mol_andk\n",
    "\n",
    "# compute coefficient and molecular accuracies of formulas\n",
    "def accuracies_top_k(mol_matching_fn, true, preds):\n",
    "    exact_match_list = []\n",
    "    results_mol_only_list = []\n",
    "    results_mol_andk_list = []\n",
    "    \n",
    "    for pred in preds:\n",
    "        exact_match, results_mol_only, result_mol_andk = accuracies_top_1(mol_matching_fn, true, pred)\n",
    "        exact_match_list.append(exact_match)\n",
    "        results_mol_only_list.append(results_mol_only)\n",
    "        results_mol_andk_list.append(result_mol_andk)\n",
    "    \n",
    "    return exact_match_list, results_mol_only_list, results_mol_andk_list\n",
    "\n",
    "def get_coef_and_mol(split, representation):\n",
    "    # we assume that the correct format is {N}MOLECULE, where N is a positive number\n",
    "    # and MOLECULE is either a chemical formula or a SMILES string.\n",
    "    # The stechiometric coefficient {N} must always be at the beginning of the string\n",
    "    coef_pattern = re.compile(\"{[0-9]+}\")\n",
    "    coef_match = coef_pattern.match(split)\n",
    "\n",
    "    # if cannot find coefficient, then consider all string as the molecule\n",
    "    # otherwise (standard case), the molecule lies at the right of coefficient\n",
    "    if not coef_match:\n",
    "        coef_str = None\n",
    "        mol_str = split        \n",
    "    else:\n",
    "        mol_str = split[coef_match.end():]\n",
    "        coef_str = int(coef_match.group()[1:-1])\n",
    "        \n",
    "    try:\n",
    "        if representation == \"smiles\":\n",
    "            mol_obj = Chem.MolFromSmiles(mol_str)\n",
    "            mol_str = Chem.MolToSmiles(mol_obj)\n",
    "            mol_str = Chem.CanonSmiles(mol_str)\n",
    "    except:\n",
    "        #print(\"mol_str:\", mol_str)\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    return (coef_str, mol_str)\n",
    "\n",
    "\n",
    "\n",
    "def compute_accuracy(prediction_path, data_path_src, data_path_tgt, representation, top_k=1, beam_width=1, test_split=\"test-in\"):\n",
    "    with open(data_path_src, 'r') as fp:\n",
    "        source_lines = fp.readlines()\n",
    "    with open(data_path_tgt, 'r') as fp:\n",
    "        target_lines = fp.readlines()\n",
    "    with open(prediction_path, \"r\") as fp:\n",
    "        pred_lines = fp.readlines()\n",
    "    \n",
    "    assert representation in [\"smiles\", \"formula\"]\n",
    "\n",
    "    remove_whitespaces = str.maketrans('', '', string.whitespace)  # used for removing whitespaces.\n",
    "\n",
    "    # predictions now have a list length of beam_size * test_size, reshape it\n",
    "    new_pred_lines = []\n",
    "    for c, pred in enumerate(pred_lines):\n",
    "        if c % beam_width == 0:\n",
    "            new_pred_lines.append([pred])\n",
    "        else:\n",
    "            new_pred_lines[-1].append(pred)\n",
    "\n",
    "    assert top_k <= beam_width\n",
    "\n",
    "    # keep only the top_k prediction fo reach line\n",
    "    for i in range(len(new_pred_lines)):\n",
    "        new_pred_lines[i] = new_pred_lines[i][:top_k]\n",
    "\n",
    "    # now for each prediciton line we have a list of predictions, corresponding to the top_k predictions\n",
    "    \n",
    "    print(\"source lines:\", len(source_lines), \"target_lines:\", len(target_lines), \"pred_lines:\", len(new_pred_lines))\n",
    "    \n",
    "    assert len(source_lines) == len(target_lines) == len(new_pred_lines)\n",
    "    \n",
    "    final_results = {\n",
    "        \"EM\": [],\n",
    "        \"only_mol\": {\n",
    "            \"ACC\": [],\n",
    "            \"PRE\": [],\n",
    "            \"REC\": [],\n",
    "            \"F1\": [],\n",
    "            \"HL\": []\n",
    "        },\n",
    "       \"mol_andk\": {\n",
    "            \"ACC\": [],\n",
    "            \"PRE\": [],\n",
    "            \"REC\": [],\n",
    "            \"F1\": [],\n",
    "            \"HL\": []\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    for source, target, top_k_predictions in tqdm.tqdm(zip(source_lines, target_lines, new_pred_lines), total=len(target_lines)):        \n",
    "        \n",
    "        # preprocessing: removes whitespaces\n",
    "        source = source.translate(remove_whitespaces)\n",
    "        target = target.translate(remove_whitespaces)\n",
    "        top_k_preds = [ pred.translate(remove_whitespaces) for pred in top_k_predictions ]\n",
    "\n",
    "        source_splits = source.split(\".\")\n",
    "        target_splits = target.split(\".\")\n",
    "        top_k_preds_splits = [ pred.split(\".\") for pred in top_k_preds ]\n",
    "        \n",
    "        \n",
    "        # parse the lines, identifying coefficient and molecules\n",
    "        # filter out molecules that cannot be parsed\n",
    "        # (for which get_coef_and_mol(kmol) == None)\n",
    "        src_k_mol = [\n",
    "            get_coef_and_mol(kmol, representation)\n",
    "            for kmol in source_splits\n",
    "        ]\n",
    "        src_k_mol = list(filter(lambda x: x, src_k_mol))\n",
    "\n",
    "        tgt_k_mol = [\n",
    "            get_coef_and_mol(kmol, representation)\n",
    "            for kmol in target_splits\n",
    "        ]\n",
    "        tgt_k_mol = list(filter(lambda x: x, tgt_k_mol))\n",
    "        \n",
    "        pred_k_mols = [\n",
    "            list(filter(lambda x: x,\n",
    "            [\n",
    "                get_coef_and_mol(kmol, representation)\n",
    "                for kmol in pred_splits\n",
    "            ]\n",
    "            ))\n",
    "            for pred_splits in top_k_preds_splits\n",
    "        ]\n",
    "     \n",
    "        #print(\"PRED K MOLS::\")\n",
    "        #pprint(pred_k_mols)\n",
    "        \n",
    "        # the matcvhing function must determine wether two strings\n",
    "        # represent the same molecule\n",
    "        \n",
    "        def smiles_matching_fn(mol_true, mol_pred):\n",
    "            return Chem.CanonSmiles(mol_true) == Chem.CanonSmiles(mol_pred)\n",
    "        \n",
    "        def formula_matching_fn(mol_true, mol_pred):\n",
    "            return mol_true == mol_pred\n",
    "        \n",
    "        if representation == \"smiles\":\n",
    "            matching_fn = smiles_matching_fn\n",
    "        else:\n",
    "            matching_fn = formula_matching_fn\n",
    "        \n",
    "        exact_matches, metrics_only_mol, metrics_mol_andk = accuracies_top_k(\n",
    "            matching_fn,\n",
    "            tgt_k_mol,\n",
    "            pred_k_mols\n",
    "        )\n",
    "        \n",
    "        \n",
    "        # TODO for the time being consider only top-1\n",
    "        final_results[\"EM\"].append(exact_matches[0])\n",
    "        \n",
    "        final_results[\"only_mol\"][\"ACC\"].append(metrics_only_mol[0][\"accuracy\"])\n",
    "        final_results[\"only_mol\"][\"PRE\"].append(metrics_only_mol[0][\"precision\"])\n",
    "        final_results[\"only_mol\"][\"REC\"].append(metrics_only_mol[0][\"recall\"])\n",
    "        final_results[\"only_mol\"][\"F1\"].append(metrics_only_mol[0][\"f1_score\"])\n",
    "        final_results[\"only_mol\"][\"HL\"].append(metrics_only_mol[0][\"hamming_loss\"])\n",
    "        \n",
    "        final_results[\"mol_andk\"][\"ACC\"].append(metrics_mol_andk[0][\"accuracy\"])\n",
    "        final_results[\"mol_andk\"][\"PRE\"].append(metrics_mol_andk[0][\"precision\"])\n",
    "        final_results[\"mol_andk\"][\"REC\"].append(metrics_mol_andk[0][\"recall\"])\n",
    "        final_results[\"mol_andk\"][\"F1\"].append(metrics_mol_andk[0][\"f1_score\"])\n",
    "        final_results[\"mol_andk\"][\"HL\"].append(metrics_mol_andk[0][\"hamming_loss\"])\n",
    "    \n",
    "    final_results[\"EM\"] = np.array(final_results[\"EM\"]).mean()\n",
    "    \n",
    "    final_results[\"only_mol\"][\"ACC\"] = np.array(final_results[\"only_mol\"][\"ACC\"]).mean()\n",
    "    final_results[\"only_mol\"][\"PRE\"] = np.array(final_results[\"only_mol\"][\"PRE\"]).mean()\n",
    "    final_results[\"only_mol\"][\"REC\"] = np.array(final_results[\"only_mol\"][\"REC\"]).mean()\n",
    "    final_results[\"only_mol\"][\"F1\"] = np.array(final_results[\"only_mol\"][\"F1\"]).mean()\n",
    "    final_results[\"only_mol\"][\"HL\"] = np.array(final_results[\"only_mol\"][\"HL\"]).mean()\n",
    "    \n",
    "    final_results[\"mol_andk\"][\"ACC\"] = np.array(final_results[\"mol_andk\"][\"ACC\"]).mean()\n",
    "    final_results[\"mol_andk\"][\"PRE\"] = np.array(final_results[\"mol_andk\"][\"PRE\"]).mean()\n",
    "    final_results[\"mol_andk\"][\"REC\"] = np.array(final_results[\"mol_andk\"][\"REC\"]).mean()\n",
    "    final_results[\"mol_andk\"][\"F1\"] = np.array(final_results[\"mol_andk\"][\"F1\"]).mean()\n",
    "    final_results[\"mol_andk\"][\"HL\"] = np.array(final_results[\"mol_andk\"][\"HL\"]).mean()\n",
    "    \n",
    "    print(\"*** FINAL RESULTS for\", test_split,\"***\")\n",
    "    pprint(final_results)\n",
    "    \n",
    "    print(\"ALL GOOD!\")\n",
    "    \n",
    "    \n",
    "###################################   \n",
    "#          ### MAIN ###           #\n",
    "###################################\n",
    "\n",
    "#model_name = \"TRANS_FINAL_RUN\"\n",
    "model_name = \"TRANS_FINAL_RUN_CROSS\"\n",
    "\n",
    "_TYPE = 2\n",
    "N_AUGM = 5\n",
    "REPRESENTATION = \"smiles\"\n",
    "\n",
    "TOP_K = 3\n",
    "BEAM_WIDTH = 10\n",
    "\n",
    "dataset_name = \"USPTO_augmented_type\" + str(_TYPE) + \"_x\" + str(N_AUGM) + \"_\" + REPRESENTATION\n",
    "predictions_path_prefix = os.path.join(\"./ChemAlgebra_results\", \"final_predictions\", model_name + \"_on_\" + dataset_name)\n",
    "data_path_prefix = os.path.join(\"./ChemAlgebra_results\", \"data\", dataset_name)\n",
    "\n",
    "#predictions_path_prefix = \"./ChemAlgebra_results/final_predictions/TRANS_STANDARD_ARCH_smiles_type1_x1_on_USPTO_augmented_type1_x1_smiles\"\n",
    "#data_path_prefix = \"./ChemAlgebra_results/data/USPTO_augmented_type1_x1_smiles\"\n",
    "\n",
    "if True:\n",
    "    if False:\n",
    "        compute_accuracy(\n",
    "            predictions_path_prefix + \"_test_in_final.txt\",\n",
    "            data_path_prefix + \"/src-test_in_x1.txt\",\n",
    "            data_path_prefix + \"/tgt-test_in_x1.txt\",\n",
    "            top_k=TOP_K,\n",
    "            representation=REPRESENTATION,\n",
    "            beam_width=BEAM_WIDTH,\n",
    "            test_split=\"test_in\"\n",
    "        )\n",
    "    \n",
    "        compute_accuracy(\n",
    "            predictions_path_prefix + \"_test_out_final.txt\",\n",
    "            data_path_prefix + \"/src-test_out_x1.txt\",\n",
    "            data_path_prefix + \"/tgt-test_out_x1.txt\",\n",
    "            top_k=TOP_K,\n",
    "            representation=REPRESENTATION,\n",
    "            beam_width=BEAM_WIDTH,\n",
    "            test_split=\"test_out\"\n",
    "        )    \n",
    "    if True:\n",
    "        compute_accuracy(\n",
    "            predictions_path_prefix + \"_test_cross_final.txt\",\n",
    "            data_path_prefix + \"/src-test_cross.txt\",\n",
    "            data_path_prefix + \"/tgt-test_cross.txt\",\n",
    "            top_k=TOP_K,\n",
    "            representation=REPRESENTATION,\n",
    "            beam_width=BEAM_WIDTH,\n",
    "            test_split=\"test_cross\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5471938-1fb7-4e29-b0c9-f09201248aac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689bbac3-98a1-4ce7-b227-005fe7e53296",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a64ac9-e8f3-4614-8364-fd8fd723c009",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
